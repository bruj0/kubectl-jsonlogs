#!/usr/bin/env python3
"""
kubectl-jsonlogs: A kubectl plugin to parse and colorize JSON and timestamped logs.
Works as both a kubectl plugin and k9s plugin.

Usage:
    # As kubectl plugin (pipe mode):
    kubectl logs <pod> | kubectl jsonlogs
    
    # As k9s plugin (direct mode):
    kubectl jsonlogs <name> <namespace> <context> [container]
    
    # When container is not specified, shows logs from all containers

Features:
    - Pretty-prints JSON logs with jq-like colorization
    - Colorizes timestamped non-JSON logs
    - Supports pods view: automatically tails logs from all containers
    - Highlights container names in bold cyan for multi-container pods
    - Minimal dependencies (uses only Python standard library)
    - Optional virtual environment support
"""

import json
import re
import subprocess
import sys
from datetime import datetime
from typing import Optional, Tuple

# ANSI color codes (no external dependencies)
class Colors:
    RESET = '\033[0m'
    BOLD = '\033[1m'
    
    # JSON colors (jq-like)
    JSON_KEY = '\033[34m'      # Blue
    JSON_STRING = '\033[32m'   # Green
    JSON_NUMBER = '\033[35m'   # Magenta
    JSON_BOOLEAN = '\033[33m'  # Yellow
    JSON_NULL = '\033[90m'     # Dark gray
    JSON_BRACE = '\033[36m'    # Cyan
    
    # Log level colors
    ERROR = '\033[31m'         # Red
    WARN = '\033[33m'          # Yellow
    INFO = '\033[36m'          # Cyan
    DEBUG = '\033[90m'         # Dark gray
    
    # Timestamp color
    TIMESTAMP = '\033[90m'     # Dark gray
    
    # Pulumi output colors
    PULUMI_RESOURCE_CREATING = '\033[32m'  # Green for creating
    PULUMI_RESOURCE_UPDATING = '\033[33m'  # Yellow for updating
    PULUMI_RESOURCE_CREATED = '\033[32m'   # Green for created
    PULUMI_SECTION_HEADER = '\033[1m\033[36m'  # Bold cyan for section headers
    PULUMI_DURATION = '\033[35m'  # Magenta for duration
    PULUMI_STATUS = '\033[36m'    # Cyan for status indicators


def is_pulumi_output(text: str) -> bool:
    """Check if a string contains Pulumi output."""
    if not text:
        return False
    # Check for common Pulumi patterns
    pulumi_patterns = [
        r'pulumi:pulumi:Stack',
        r'Resource Updated',
        r'Updating \(resource\)',
        r'Previewing update',
        r'@ updating',
        r'@ previewing',
        r'Outputs:',
        r'Resources:',
        r'Duration:',
        r'\+\s+\w+:\w+:',  # Resource type pattern like "aws:iam:Policy"
        r'pulumi up failed',  # Error patterns
        r'failed to run update',
        r'error: \d+ error occurred',
        r'creating failed',
        r'\*\*failed\*\*',
        r'Diagnostics:',
        r'operation failed',
    ]
    return any(re.search(pattern, text) for pattern in pulumi_patterns)


def format_pulumi_output(text: str) -> str:
    """Format and colorize Pulumi output."""
    lines = text.split('\n')
    formatted_lines = []
    
    for line in lines:
        if not line.strip():
            formatted_lines.append('')
            continue
        
        # Section headers (Outputs:, Resources:, Duration:)
        section_match = re.match(r'^(Outputs|Resources|Duration):\s*(.*)', line)
        if section_match:
            section_name = section_match.group(1)
            section_value = section_match.group(2)
            if section_value:
                formatted_lines.append(f"{Colors.PULUMI_SECTION_HEADER}{section_name}:{Colors.RESET} {section_value}")
            else:
                formatted_lines.append(f"{Colors.PULUMI_SECTION_HEADER}{section_name}:{Colors.RESET}")
            continue
        
        # Resource status lines: +  pulumi:pulumi:Stack ... creating (0s) or ... create
        # Pattern: +  pulumi:pulumi:Stack appauth-e2e-test-e2e-clientapp-1208170521-local-da57-resource creating (0s)
        # Pattern: +  pulumi:pulumi:Stack schedule-e2e-test-e2e-schedule-1208170809-617-b4b2-resource create
        resource_match_with_time = re.match(r'^(\s*)([+\-~])\s+([^\s]+(?::[^\s]+)*)\s+(.+?)\s+(\w+)\s+\(([^)]+)\)\s*$', line)
        resource_match_no_time = re.match(r'^(\s*)([+\-~])\s+([^\s]+(?::[^\s]+)*)\s+(.+?)\s+(\w+)\s*$', line)
        
        if resource_match_with_time:
            indent = resource_match_with_time.group(1)
            symbol = resource_match_with_time.group(2)
            resource_type = resource_match_with_time.group(3)
            resource_name = resource_match_with_time.group(4)
            status = resource_match_with_time.group(5)
            time = resource_match_with_time.group(6)
            
            # Determine color based on status
            if 'failed' in status.lower():
                status_color = Colors.ERROR
            elif 'creating' in status.lower():
                status_color = Colors.PULUMI_RESOURCE_CREATING
            elif 'updating' in status.lower():
                status_color = Colors.PULUMI_RESOURCE_UPDATING
            elif 'created' in status.lower() or 'updated' in status.lower():
                status_color = Colors.PULUMI_RESOURCE_CREATED
            else:
                status_color = Colors.PULUMI_STATUS
            
            formatted_line = f"{indent}{symbol}  {Colors.JSON_BRACE}{resource_type}{Colors.RESET} {resource_name} {status_color}{status} ({time}){Colors.RESET}"
            formatted_lines.append(formatted_line)
            continue
        elif resource_match_no_time:
            indent = resource_match_no_time.group(1)
            symbol = resource_match_no_time.group(2)
            resource_type = resource_match_no_time.group(3)
            resource_name = resource_match_no_time.group(4)
            status = resource_match_no_time.group(5)
            
            # Determine color based on status
            if 'failed' in status.lower():
                status_color = Colors.ERROR
            elif 'create' in status.lower():
                status_color = Colors.PULUMI_RESOURCE_CREATING
            elif 'update' in status.lower():
                status_color = Colors.PULUMI_RESOURCE_UPDATING
            else:
                status_color = Colors.PULUMI_STATUS
            
            formatted_line = f"{indent}{symbol}  {Colors.JSON_BRACE}{resource_type}{Colors.RESET} {resource_name} {status_color}{status}{Colors.RESET}"
            formatted_lines.append(formatted_line)
            continue
        
        # Status indicators: @ updating.... or @ previewing update....
        if re.match(r'^@\s+(updating|previewing)', line, re.IGNORECASE):
            formatted_lines.append(f"{Colors.PULUMI_RESOURCE_UPDATING}{line}{Colors.RESET}")
            continue
        
        # Output values: roleArn: "arn:aws:iam::..."
        # Pattern:     roleArn: "arn:aws:iam::429583250656:role/e2e-test-e2e-clientapp-1208170521-local-da57-sa-role"
        output_match = re.match(r'^(\s+)(\w+):\s+(.+)', line)
        if output_match:
            indent = output_match.group(1)
            key = output_match.group(2)
            value = output_match.group(3)
            formatted_lines.append(f"{indent}{Colors.JSON_KEY}{key}{Colors.RESET}: {Colors.JSON_STRING}{value}{Colors.RESET}")
            continue
        
        # Summary lines: + 5 created or + 2 to create
        # Match "to create" first, then other actions (order matters - longer matches first)
        summary_match = re.match(r'^(\s*)([+\-])\s+(\d+)\s+(to\s+)?(created|updated|deleted|create)', line, re.IGNORECASE)
        if summary_match:
            indent = summary_match.group(1)
            symbol = summary_match.group(2)
            count = summary_match.group(3)
            to_prefix = summary_match.group(4) or ''
            action = summary_match.group(5)
            formatted_lines.append(f"{indent}{symbol} {Colors.JSON_NUMBER}{count}{Colors.RESET} {Colors.PULUMI_RESOURCE_CREATED}{to_prefix}{action}{Colors.RESET}")
            continue
        
        # Duration line: Duration: 5s
        duration_match = re.match(r'^Duration:\s*(.+)', line)
        if duration_match:
            duration = duration_match.group(1)
            formatted_lines.append(f"{Colors.PULUMI_SECTION_HEADER}Duration:{Colors.RESET} {Colors.PULUMI_DURATION}{duration}{Colors.RESET}")
            continue
        
        # Text lines like "Resource Updated Updating (resource):" or "Previewing update (resource):"
        if re.search(r'(Resource (Updated|Created|Deleted)|Previewing update|Updating \(resource\))', line, re.IGNORECASE):
            formatted_lines.append(f"{Colors.PULUMI_SECTION_HEADER}{line}{Colors.RESET}")
            continue
        
        # Error messages: "error: 1 error occurred:" or "error: update failed"
        error_match = re.match(r'^(\s*)error:\s+(.+)', line, re.IGNORECASE)
        if error_match:
            indent = error_match.group(1)
            error_msg = error_match.group(2)
            formatted_lines.append(f"{indent}{Colors.ERROR}error:{Colors.RESET} {Colors.ERROR}{error_msg}{Colors.RESET}")
            continue
        
        # Failed status indicators: "**failed**" or "creating failed"
        if re.search(r'\*\*failed\*\*|creating failed|update failed', line, re.IGNORECASE):
            formatted_lines.append(f"{Colors.ERROR}{line}{Colors.RESET}")
            continue
        
        # Diagnostics section header
        diagnostics_match = re.match(r'^(\s*)Diagnostics:\s*$', line)
        if diagnostics_match:
            indent = diagnostics_match.group(1)
            formatted_lines.append(f"{indent}{Colors.PULUMI_SECTION_HEADER}Diagnostics:{Colors.RESET}")
            continue
        
        # AWS error types: "NotFoundException:", "ValidationException:", etc.
        aws_error_match = re.match(r'^(\s*)(\w+Exception):\s+(.+)', line)
        if aws_error_match:
            indent = aws_error_match.group(1)
            error_type = aws_error_match.group(2)
            error_msg = aws_error_match.group(3)
            formatted_lines.append(f"{indent}{Colors.ERROR}{error_type}:{Colors.RESET} {Colors.ERROR}{error_msg}{Colors.RESET}")
            continue
        
        # Stack trace lines (usually start with tabs/spaces and contain file paths)
        if re.match(r'^\s+.*\.(go|py|js|ts|java):\d+', line):
            formatted_lines.append(f"{Colors.DEBUG}{line}{Colors.RESET}")
            continue
        
        # Operation failed messages: "operation failed (attempt 1/3):"
        operation_failed_match = re.match(r'^(\s*)operation failed\s*\((.+)\):\s*(.+)', line, re.IGNORECASE)
        if operation_failed_match:
            indent = operation_failed_match.group(1)
            attempt_info = operation_failed_match.group(2)
            error_detail = operation_failed_match.group(3)
            formatted_lines.append(f"{indent}{Colors.ERROR}operation failed ({attempt_info}):{Colors.RESET} {Colors.ERROR}{error_detail}{Colors.RESET}")
            continue
        
        # Default: keep original line
        formatted_lines.append(line)
    
    return '\n'.join(formatted_lines)


def colorize_json_string(json_str: str, indent: int = 2) -> str:
    """Colorize a JSON string similar to jq output."""
    try:
        obj = json.loads(json_str)
        return colorize_json_value(obj, indent=indent, level=0)
    except json.JSONDecodeError:
        return json_str


def colorize_json_value(value, indent: int = 2, level: int = 0, key_name: Optional[str] = None) -> str:
    """Recursively colorize JSON values."""
    if value is None:
        return f"{Colors.JSON_NULL}null{Colors.RESET}"
    elif isinstance(value, bool):
        color = Colors.JSON_BOOLEAN
        return f"{color}{str(value).lower()}{Colors.RESET}"
    elif isinstance(value, (int, float)):
        return f"{Colors.JSON_NUMBER}{value}{Colors.RESET}"
    elif isinstance(value, str):
        # Escape special characters for display
        escaped = json.dumps(value)
        return f"{Colors.JSON_STRING}{escaped}{Colors.RESET}"
    elif isinstance(value, dict):
        if not value:
            return f"{Colors.JSON_BRACE}{{}}{Colors.RESET}"
        
        lines = [f"{Colors.JSON_BRACE}{{{Colors.RESET}"]
        items = list(value.items())
        for i, (k, v) in enumerate(items):
            key_part = f"{Colors.JSON_KEY}{json.dumps(str(k))}{Colors.RESET}"
            indent_str = " " * ((level + 1) * indent)
            comma = "," if i < len(items) - 1 else ""
            
            # Special handling for 'msg', 'output', and 'error' fields with Pulumi output - format it as multi-line
            if str(k) in ('msg', 'output', 'error') and isinstance(v, str) and is_pulumi_output(v):
                # Format the Pulumi output
                formatted_pulumi = format_pulumi_output(v)
                # Split into lines and indent each line
                pulumi_lines = formatted_pulumi.split('\n')
                if len(pulumi_lines) > 1:
                    # Multi-line format - display as a formatted block
                    # Start with the key
                    lines.append(f"{indent_str}{key_part}:")
                    # Find the last non-empty line index before adding lines
                    last_non_empty_idx = -1
                    for i, pulumi_line in enumerate(pulumi_lines):
                        # Indent each line with extra spacing
                        lines.append(f"{indent_str}  {pulumi_line}")
                        if pulumi_line.strip():
                            last_non_empty_idx = len(lines) - 1
                    # Add comma to the last non-empty line if needed
                    if comma and last_non_empty_idx >= 0:
                        lines[last_non_empty_idx] = lines[last_non_empty_idx] + comma
                    continue
            
            # Pass the key name for special handling (e.g., 'msg' field)
            value_part = colorize_json_value(v, indent, level + 1, key_name=str(k))
            lines.append(f"{indent_str}{key_part}: {value_part}{comma}")
        lines.append(f"{' ' * (level * indent)}{Colors.JSON_BRACE}}}{Colors.RESET}")
        return "\n".join(lines)
    elif isinstance(value, list):
        if not value:
            return f"{Colors.JSON_BRACE}[]{Colors.RESET}"
        
        lines = [f"{Colors.JSON_BRACE}[{Colors.RESET}"]
        for i, item in enumerate(value):
            value_part = colorize_json_value(item, indent, level + 1, key_name=None)
            comma = "," if i < len(value) - 1 else ""
            indent_str = " " * ((level + 1) * indent)
            lines.append(f"{indent_str}{value_part}{comma}")
        lines.append(f"{' ' * (level * indent)}{Colors.JSON_BRACE}]{Colors.RESET}")
        return "\n".join(lines)
    else:
        return str(value)


def detect_log_level(line: str) -> Optional[str]:
    """Detect log level in a line (case-insensitive)."""
    line_lower = line.lower()
    if re.search(r'\b(error|err|exception|fatal|critical)\b', line_lower):
        return 'ERROR'
    elif re.search(r'\b(warn|warning)\b', line_lower):
        return 'WARN'
    elif re.search(r'\b(debug|trace)\b', line_lower):
        return 'DEBUG'
    elif re.search(r'\b(info|information)\b', line_lower):
        return 'INFO'
    return None


def colorize_timestamped_line(line: str) -> str:
    """Colorize a timestamped log line."""
    colored_line = line
    
    # Colorize container name prefix from kubectl --all-containers (format: [container-name])
    container_prefix_pattern = r'^(\[[^\]]+\])\s+'
    container_match = re.match(container_prefix_pattern, line)
    if container_match:
        container_prefix = container_match.group(1)
        # Use bold cyan for container names to make them stand out
        colored_prefix = f"{Colors.BOLD}{Colors.JSON_BRACE}{container_prefix}{Colors.RESET} "
        colored_line = colored_prefix + line[len(container_prefix):].lstrip()
    
    # Common timestamp patterns (ISO 8601, RFC3339, common log formats)
    timestamp_patterns = [
        r'(\d{4}-\d{2}-\d{2}[T ]\d{2}:\d{2}:\d{2}(?:\.\d+)?(?:Z|[+-]\d{2}:\d{2})?)',  # ISO 8601
        r'(\d{4}/\d{2}/\d{2} \d{2}:\d{2}:\d{2})',  # YYYY/MM/DD HH:MM:SS
        r'(\[(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})\])',  # [YYYY-MM-DD HH:MM:SS]
        r'(\d{2}/\w{3}/\d{4}:\d{2}:\d{2}:\d{2})',  # DD/Mon/YYYY:HH:MM:SS (nginx style)
    ]
    
    for pattern in timestamp_patterns:
        match = re.search(pattern, colored_line)
        if match:
            timestamp = match.group(1) if match.lastindex else match.group(0)
            colored_timestamp = f"{Colors.TIMESTAMP}{timestamp}{Colors.RESET}"
            colored_line = colored_line.replace(timestamp, colored_timestamp, 1)
            break
    
    # Colorize log level if detected
    log_level = detect_log_level(line)
    if log_level:
        if log_level == 'ERROR':
            colored_line = f"{Colors.ERROR}{colored_line}{Colors.RESET}"
        elif log_level == 'WARN':
            colored_line = f"{Colors.WARN}{colored_line}{Colors.RESET}"
        elif log_level == 'INFO':
            colored_line = f"{Colors.INFO}{colored_line}{Colors.RESET}"
        elif log_level == 'DEBUG':
            colored_line = f"{Colors.DEBUG}{colored_line}{Colors.RESET}"
    
    return colored_line


def process_line(line: str) -> str:
    """Process a single log line - try JSON first, then timestamped log."""
    line = line.rstrip('\n\r')
    
    # Extract container name prefix if present (from kubectl --all-containers)
    container_prefix = None
    container_prefix_pattern = r'^(\[[^\]]+\])\s+'
    container_match = re.match(container_prefix_pattern, line)
    if container_match:
        container_prefix = container_match.group(1)
        # Remove prefix temporarily for JSON parsing
        line_without_prefix = line[len(container_prefix):].lstrip()
    else:
        line_without_prefix = line
    
    # Try to parse as JSON (without container prefix)
    try:
        # Attempt to parse the line as JSON
        json.loads(line_without_prefix)
        colored_json = colorize_json_string(line_without_prefix)
        # Add container prefix back if it existed
        if container_prefix:
            colored_prefix = f"{Colors.BOLD}{Colors.JSON_BRACE}{container_prefix}{Colors.RESET} "
            return colored_prefix + colored_json
        return colored_json
    except json.JSONDecodeError:
        pass
    
    # Try to find JSON objects within the line (without container prefix)
    json_pattern = r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}'
    matches = re.finditer(json_pattern, line_without_prefix)
    
    if matches:
        result = line_without_prefix
        offset = 0
        for match in matches:
            json_str = match.group(0)
            try:
                # Validate it's actually JSON
                json.loads(json_str)
                colored_json = colorize_json_string(json_str)
                start, end = match.span()
                # Replace the JSON part with colored version
                result = result[:start + offset] + colored_json + result[end + offset:]
                offset += len(colored_json) - len(json_str)
            except json.JSONDecodeError:
                continue
        
        # Colorize the rest of the line (timestamps, etc.)
        if result != line_without_prefix:
            # Extract non-JSON parts and colorize them
            parts = re.split(json_pattern, result)
            colored_parts = [colorize_timestamped_line(part) if part.strip() else part 
                           for part in parts]
            colored_result = ''.join(colored_parts)
            # Add container prefix back if it existed
            if container_prefix:
                colored_prefix = f"{Colors.BOLD}{Colors.JSON_BRACE}{container_prefix}{Colors.RESET} "
                return colored_prefix + colored_result
            return colored_result
    
    # Not JSON, treat as timestamped log (this will handle container prefix)
    return colorize_timestamped_line(line)


def load_venv_if_needed():
    """
    Simple virtual environment loader.
    
    Looks for a virtual environment in common locations:
    - $HOME/.venv/ (default)
    - $HOME/.kubectl-logs-venv/
    - ./venv/
    - ./.venv/
    - ../venv/
    
    To use: Create a venv and install any optional dependencies there.
    """
    import os
    import sys
    from pathlib import Path
    
    script_dir = Path(__file__).parent.absolute()
    home_venv = Path.home() / '.venv'
    home_kubectl_logs_venv = Path.home() / '.kubectl-logs-venv'
    possible_venvs = [
        home_venv,  # Default location: $HOME/.venv
        home_kubectl_logs_venv,  # Plugin-specific location: $HOME/.kubectl-logs-venv
        script_dir / 'venv',
        script_dir / '.venv',
        script_dir.parent / 'venv',
    ]
    
    for venv_path in possible_venvs:
        if venv_path.exists():
            # Modern approach: add venv site-packages to sys.path
            site_packages = venv_path / 'lib' / f'python{sys.version_info.major}.{sys.version_info.minor}' / 'site-packages'
            if site_packages.exists() and str(site_packages) not in sys.path:
                sys.path.insert(0, str(site_packages))
                return True
            
            # Fallback: try activate_this.py (for older venv setups)
            activate_script = venv_path / 'bin' / 'activate_this.py'
            if activate_script.exists():
                try:
                    exec(open(activate_script).read(), {'__file__': str(activate_script)})
                    return True
                except Exception:
                    pass
    
    return False


def execute_kubectl_logs(pod_name: str, namespace: str, context: str, container: Optional[str] = None):
    """Execute kubectl logs command with the given parameters.
    
    Args:
        pod_name: Name of the pod
        namespace: Kubernetes namespace
        context: Kubernetes context
        container: Container name (optional, if not provided uses --all-containers)
    """
    cmd = ['kubectl', 'logs']
    
    if namespace and namespace != '':
        cmd.extend(['-n', namespace])
    
    if context and context != '':
        cmd.extend(['--context', context])
    
    # Always use the specified container if provided, otherwise use --all-containers
    # For container scope in k9s, container will always be provided
    if container and container != '':
        cmd.extend(['-c', container])
    else:
        # Fallback: use all containers only if no container is specified
        cmd.append('--all-containers')
    
    # Add follow flag for real-time logs
    cmd.extend(['-f', pod_name])
    
    process = None
    try:
        process = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            universal_newlines=True,
            bufsize=1
        )
        
        # Process output line by line
        for line in process.stdout:
            try:
                colored_line = process_line(line)
                print(colored_line, end='')
                sys.stdout.flush()
            except Exception:
                # If processing fails, just print the original line
                print(line, end='')
                sys.stdout.flush()
        
        process.wait()
        return process.returncode
    except KeyboardInterrupt:
        if process:
            process.terminate()
        sys.exit(0)
    except Exception as e:
        print(f"Error executing kubectl logs: {e}", file=sys.stderr)
        return 1


def main():
    """Main entry point."""
    # Try to load virtual environment if available
    load_venv_if_needed()
    
    # Check if output is a TTY for color support
    if not sys.stdout.isatty():
        # If not a TTY, disable colors
        for attr in dir(Colors):
            if not attr.startswith('_'):
                setattr(Colors, attr, '')
    
    # Check if we're being called with k9s arguments (k9s mode)
    # k9s passes: pod, namespace, context, container (from container scope)
    # Args: $POD, $NAMESPACE, $CONTEXT, $NAME (where $NAME is the container name)
    if len(sys.argv) >= 4:
        pod_name = sys.argv[1]  # $POD - pod name
        namespace = sys.argv[2]  # $NAMESPACE
        context = sys.argv[3]  # $CONTEXT
        container = sys.argv[4] if len(sys.argv) > 4 and sys.argv[4] != '' else None  # $NAME - container name
        
        # Execute kubectl logs and process output
        exit_code = execute_kubectl_logs(pod_name, namespace, context, container)
        sys.exit(exit_code if exit_code else 0)
    
    # Otherwise, process stdin (pipe mode)
    try:
        for line in sys.stdin:
            try:
                colored_line = process_line(line)
                print(colored_line, end='')
            except Exception as e:
                # If processing fails, just print the original line
                print(line, end='')
    except KeyboardInterrupt:
        sys.exit(0)
    except BrokenPipeError:
        # Handle pipe breaks gracefully (e.g., when piping to head)
        sys.exit(0)


if __name__ == '__main__':
    main()

